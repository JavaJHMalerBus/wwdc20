/*:
 [Previous](@previous)
 # Epilogue
 Although - what might differentiate this submission from many others - I could not appropriately use things like Audio, I hope I could showcase a great technology which in my opinion has a great future.
 
 ## Hidden code
 As you might have seen, I have hidden some code to keep the pages at least in some way clear. If you are interested, you can find the full code on the pages linked below.
 
 # Conclusion
 Finally, we have reached the end of my playground. But what what is my conclusion? What did this show us about CoreML and Vision?
 First of all, I want to state that, in my opinion, both frameworks are great but have a different “main” purpose. Vision is a great tool for combining artificial intelligence with images or video, whereas CoreML, though it can also handle this kind of load (and indirectly does so through Vision as well) well, it is not as efficient as Vision when it comes to images. The latter allows us as developers to apply machine learning to visual data without having to reinvent everything.
 But CoreML itself, in my opinion, also has very many (direct) use cases: almost everything else without a dedicated sub-framework. E.g., natural language processing (i.e., text analysis, sentiment analysis, or chatbots; for example in combination with BERT) or, when it comes to importing custom models, almost any other possible use case. At this point, the only real limitation (besides the sky) is the model size and thus the resulting app size, which can also be solved by downloading models only when a user needs them. Of course, there are also use cases that should be implemented cloud-based, but the majority can be used on the device, which means that such solutions are also compliant with data protection at this point.
 
 # More
 - [Full Sources: Processing single photos](FullSource-Static)
 - [Full Sources: Processing live camera video](FullSource-Live)
 */
